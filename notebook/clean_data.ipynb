{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c7a61a0-5cff-4805-b729-c57f1878ef73",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import Packages and Set Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "491c24f0-8b54-4e1d-87fa-1f8997043ba0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import inspect\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.patches import Patch\n",
    "from pypfopt import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "\n",
    "# Set directories\n",
    "notebook_dir = os.getcwd()\n",
    "base_dir = os.path.join(notebook_dir, '..')\n",
    "data_dir = os.path.join(base_dir, 'data')\n",
    "stock_dir = os.path.join(base_dir, 'data', 'stocks')\n",
    "src_dir = os.path.join(base_dir, 'src')\n",
    "graph_dir = os.path.join(base_dir, 'results', 'graphs')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "# Import optimal portfolio\n",
    "from optimal_portfolios import OptimalPortfolios\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f87814-092d-4dad-b32e-77dbf45feef3",
   "metadata": {},
   "source": [
    "### Clean Factor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a97cdd9d-0580-4ac6-9568-dd62425c00c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Read Fama-French 5 factors and momentum factors\n",
    "# ff6_weekly_df = pd.read_csv(os.path.join(data_dir, 'factors/ff6_weekly.csv'))\n",
    "# ff6_monthly_df = pd.read_csv(os.path.join(data_dir, 'factors/ff6_monthly.csv'))\n",
    "# ff6_yearly_df = pd.read_csv(os.path.join(data_dir, 'factors/ff6_yearly.csv'))\n",
    "\n",
    "# # Read HXZ 4 factors\n",
    "# hxz_weekly_df = pd.read_csv(os.path.join(data_dir, 'factors/hxz_weekly.csv'))\n",
    "# hxz_monthly_df = pd.read_csv(os.path.join(data_dir, 'factors/hxz_monthly.csv'))\n",
    "# hxz_yearly_df = pd.read_csv(os.path.join(data_dir, 'factors/hxz_yearly.csv'))\n",
    "\n",
    "# # Combine the weekly factors dataframes\n",
    "# factors_weekly_df = pd.merge(ff6_weekly_df, hxz_weekly_df, on='Date', how='inner')\n",
    "# factors_weekly_df.drop(columns=['RF_HXZ', 'Mkt-RF_HXZ'], inplace=True)\n",
    "# factors_weekly_df.to_csv(os.path.join(data_dir, 'factors/factors_weekly.csv'), index=False)\n",
    "\n",
    "# # Combine the monthly factors dataframes\n",
    "# factors_monthly_df = pd.merge(ff6_monthly_df, hxz_monthly_df, on='Year_Month', how='inner')\n",
    "# factors_monthly_df['Year_Month'] = pd.to_datetime(factors_monthly_df['Year_Month']).dt.to_period('M')\n",
    "# factors_monthly_df.drop(columns=['RF_HXZ', 'Mkt-RF_HXZ'], inplace=True)\n",
    "# factors_monthly_df.to_csv(os.path.join(data_dir, 'factors/factors_monthly.csv'), index=False)\n",
    "\n",
    "# # Combine the yearly factors dataframes\n",
    "# factors_yearly_df = pd.merge(ff6_yearly_df, hxz_yearly_df, on='Year', how='inner')\n",
    "# factors_yearly_df.drop(columns=['RF_HXZ', 'Mkt-RF_HXZ'], inplace=True)\n",
    "# factors_yearly_df.to_csv(os.path.join(data_dir, 'factors/factors_yearly.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380abc20-4d8d-47cf-9e67-95e04bf7566e",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9d2de57-3fdb-4a8d-8db4-61ce4b63b1da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read efficient portfolios data\n",
    "pfo_weekly_df = pd.read_csv(os.path.join(data_dir, 'stocks/pfo_weekly.csv'))\n",
    "pfo_monthly_df = pd.read_csv(os.path.join(data_dir, 'stocks/pfo_monthly.csv'))\n",
    "pfo_yearly_df = pd.read_csv(os.path.join(data_dir, 'stocks/pfo_yearly.csv'))\n",
    "\n",
    "# Read factor data\n",
    "factors_weekly_df = pd.read_csv(os.path.join(data_dir, 'factors/factors_weekly.csv'))\n",
    "factors_monthly_df = pd.read_csv(os.path.join(data_dir, 'factors/factors_monthly.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5aa11e-c658-4de4-92ef-17f895b369c9",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c4b4af5-6ac5-4d84-b784-fb5d7476d84b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_week_column(df_orginal):\n",
    "    \"\"\"\n",
    "    Create a Year_Week column using df's Date column and drop 'Date column'\n",
    "    \"\"\"\n",
    "    df_tmp = df_orginal.copy()\n",
    "    df_tmp['Date'] = pd.to_datetime(df_tmp['Date'])\n",
    "    df_tmp['Week'] = df_tmp['Date'].dt.isocalendar().week  \n",
    "    df_tmp['Year'] = df_tmp['Date'].dt.isocalendar().year\n",
    "    df_tmp['Year_Week'] = df_tmp['Year'].astype(str) + '-' + df_tmp['Week'].astype(str).str.zfill(2)\n",
    "    df_tmp.drop(columns=['Year', 'Week', 'Date'], inplace=True)\n",
    "    return df_tmp\n",
    "\n",
    "# Create Year_Week column for weekly factor\n",
    "num_pfo = 5\n",
    "factors_weekly_tmp = create_week_column(factors_weekly_df)\n",
    "    \n",
    "# Merge stock df with factor df\n",
    "covariates_weekly = pd.merge(pfo_weekly_df, factors_weekly_tmp, how='inner', on='Year_Week')\n",
    "covariates_monthly = pd.merge(pfo_monthly_df, factors_monthly_df, how='inner', on='Year_Month')\n",
    "\n",
    "# Calculate excess return\n",
    "pfo_col_names = []  # create tmp list to re-order columns\n",
    "for pfo in range(1, num_pfo+1):\n",
    "    covariates_weekly[f'R{pfo}-RF'] = covariates_weekly[f'portfolio_{pfo}'] - covariates_weekly['RF']\n",
    "    covariates_monthly[f'R{pfo}-RF'] = covariates_monthly[f'portfolio_{pfo}'] - covariates_monthly['RF']\n",
    "    covariates_weekly.drop(columns=[f'portfolio_{pfo}'], inplace=True)   \n",
    "    pfo_col_names.append(f'R{pfo}-RF')  # append the pfo name to list  \n",
    "\n",
    "# Reorder columns \n",
    "cols_remaining = covariates_weekly.columns.difference(['Year_Week'] + pfo_col_names).tolist()\n",
    "covariates_weekly = covariates_weekly[['Year_Week'] +  pfo_col_names + cols_remaining]\n",
    "covariates_monthly = covariates_monthly[['Year_Month'] + pfo_col_names + cols_remaining]\n",
    "covariates_weekly.drop(columns=['RF'], inplace=True)  # drop RF column\n",
    "covariates_monthly.drop(columns=['RF'], inplace=True)  # drop RF column\n",
    "\n",
    "# Save to csv\n",
    "# covariates_weekly.to_csv(os.path.join(data_dir, 'covariates_weekly.csv'), index=False)\n",
    "# covariates_monthly.to_csv(os.path.join(data_dir, 'covariates_monthly.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de49baab-1b16-491d-8de1-2baaceecee8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
